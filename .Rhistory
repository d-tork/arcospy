# Load the median-based linear model
library(mblm)
# Run the model
mblm(prct ~ year, mn_tdy_sp_sub_2)
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = date, y = prct)) + geom_line() + geom_smooth(method = sen) +
labs(title = "Average Annual Precipitation for Pennsylvania Station 360106",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = date, y = prct)) +
geom_line() +
geom_smooth(method = sen) +
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = date, y = prct)) +
geom_line() +
geom_smooth(method = 'sen') +
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
# Run the model
mblm(prct ~ year, mn_tdy_sp_sub_2)
sen <- function(..., weights = NULL) {
mblm::mblm(...)
}
#Define an object that run's a Thiel Sen estimator on the data
sen <- function(..., weights = NULL) {
mblm::mblm(...)
}
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = date, y = prct)) +
geom_line() +
geom_smooth(method = sen) +
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
# Recreate the same dataset as before, this time specifying a single COOP_ID of interest
mn_tdy_sp_sub_2 <- mn_tdy_sp %>%
mutate(TEMP = 5/9 * (TMAX - 32), year = lubridate::year(date), month = lubridate::month(date)) %>%
group_by(year, COOP_ID) %>%
summarize(prct = mean(TEMP, na.rm = T), LATITUDE = first(LATITUDE), LONGITUDE = first(LONGITUDE)) %>%
filter(year > 1965, COOP_ID == 210018) %>%
arrange(year)
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = year, y = prct)) +
geom_line() +
geom_smooth(method = sen) +
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
#Trn the date character to a year-character
mn_tdy_sp_sub_2 <- mn_tdy_sp_sub_2 %>% mutate(date = as.Date(as.character(year), "%Y"))
mn_tdy_sp_sub_2$date
mn_tdy_sp_sub_2$year
# Load the median-based linear model
library(mblm)
# Run the model
mblm(prct ~ year, mn_tdy_sp_sub_2)
#Define an object that run's a Thiel Sen estimator on the data
sen <- function(..., weights = NULL) {
mblm::mblm(...)
}
# Run the graph
ggplot(mn_tdy_sp_sub_2, aes(x = date, y = prct)) +
geom_line() +
geom_smooth(method = sen) +
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Temperature (Degrees Celsius)")
rnorm(100)
t.test(rnorm(100))
?t.test
# Set seed for reproducibility
set.seed(123)
# Function taht loops a one-sample t-test for Null Ho: mu = 0 versus Alt Ha: mu =/= 0
ttest <- function() {
Y <- rnorm(100)
t.ttest <- t.test(Y, alternative = "two.sided")
TypeI <- as.numeric(t.ttest$p.value < 0.05)
}
# Run function 10,000 times
U <- replicate(10000, ttest())
# Run function 10,000 times
U <- replicate(10000, ttest())
mean(U)
numeric(110)
# Set an autocorrelation term
lambda <- 0.4
# use same seed as before
set.seed(123)
# Make a new function
ttest <- function(lambda) {
# Create a numeric vector of 110 0s
Y <- numeric(110)
#For each Y[i] 0, take lambda term and multiply it by the PREVIOUS term, adding in a random value.
#This sets up autocorrelation as it relies on the previous term, and even though we are randomly adding
#an amount with mean=1 and sd=1, because it is based from a normal distribution on average the previous number
#will have an effect on the expected sum of the next number
for (i in 2:110) Y[i] <- lambda * Y[i - 1] + rnorm(1, sd = 1)
#Get past the first few setup lags
Ysamp <- Y[11:110]
t.ttest <- t.test(Ysamp, alternative = "two.sided")
TypeI <- as.numeric(t.ttest$p.value < 0.05)
}
U <- replicate(10000, ttest(lambda))
mean(U)
var(U)
# Set seed for reproducibility
set.seed(123)
# Function taht loops a one-sample t-test for Null Ho: mu = 0 versus Alt Ha: mu =/= 0
ttest <- function() {
Y <- rnorm(100)
t.ttest <- t.test(Y, alternative = "two.sided")
#Store
TypeI <- as.numeric(t.ttest$p.value < 0.05)
}
# Run function 10,000 times
U <- replicate(10000, ttest())
# Run function 10,000 times
U <- replicate(10000, ttest())
mean(U)
var()
var(U)
?var
mn_tdy_sp_sub_4 <- mn_tdy_sp_sub %>%
mutate(date=as.Date(as.character(year),"%Y") ) %>%
arrange(COOP_ID,year) %>% dplyr::select(COOP_ID,TEMP,year,date) %>%
as_tibble() %>%
group_by(COOP_ID) %>%
nest(.key = "data.tbl") %>%
mutate(data.ts = purrr::map(.x = data.tbl,
.f = tk_ts,
select  = -year,
start   = 1966,
freq    = 1)) %>%
mutate(full.ts = map(data.ts, zoo::na.approx)) %>%
mutate(fit.tau = map(full.ts, trend::sens.slope)) %>%
mutate(data.ve = map(full.ts, as.vector)) %>%
mutate(fit.tau2 = map(data.ve, modifiedmk::pwmk))
?tk_ts
install.packages("tk_ts")
install.packages("timekit")
install.packages("timetk")
library(timetk)
mn_tdy_sp_sub_4 <- mn_tdy_sp_sub %>%
mutate(date=as.Date(as.character(year),"%Y") ) %>%
arrange(COOP_ID,year) %>% dplyr::select(COOP_ID,TEMP,year,date) %>%
as_tibble() %>%
group_by(COOP_ID) %>%
nest(.key = "data.tbl") %>%
mutate(data.ts = purrr::map(.x = data.tbl,
.f = tk_ts,
select  = -year,
start   = 1966,
freq    = 1)) %>%
mutate(full.ts = map(data.ts, zoo::na.approx)) %>%
mutate(fit.tau = map(full.ts, trend::sens.slope)) %>%
mutate(data.ve = map(full.ts, as.vector)) %>%
mutate(fit.tau2 = map(data.ve, modifiedmk::pwmk))
mn_tdy_sp_sub_4$data.ve[[1]]
?tk_ts
?na.approx
?pwmk
# We can extract the results for a single one of these new variables by indexing into the new data object
# and then extracting a slide for a given nested value (i.e. a weather station)
mn_tdy_sp_sub_4$data.ve[[1]]
# We can extract the results for a single one of these new variables by indexing into the new data object
# and then extracting a slide for a given nested value (i.e. a weather station)
mn_tdy_sp_sub_4$data.ve[[34]]
# We can extract the results for a single one of these new variables by indexing into the new data object
# and then extracting a slide for a given nested value (i.e. a weather station)
mn_tdy_sp_sub_4$data.ve[[33]]
# We can extract the results for a single one of these new variables by indexing into the new data object
# and then extracting a slide for a given nested value (i.e. 1 through 33 for each of the distinct MN weather stations)
mn_tdy_sp_sub_4$data.ve[[33]]
new.mn.p <- precipitation.sub4 %>%
mutate(pval = map(fit.tau2, ~.x["P-value"])) %>%
unnest(pval, .drop = TRUE)
new.mn.p <- mn_tdy_sp_sub_4 %>%
mutate(pval = map(fit.tau2, ~.x["P-value"])) %>%
unnest(pval, .drop = TRUE)
?fit.tau2
??fittau2
head(new.mn.p)
new.mn.p
class(new.mn.p)
class(mn_tdy_sp_sub_4)
mn_tdy_sp_sub_4
new_mn_p <- mn_tdy_sp_sub_4 %>%
#Generate a new value called pval that extracts the column P-value from the Mann-Kendall test above
mutate(pval = map(fit.tau2, ~.x["P-value"])) %>%
#Unness the pvcal variable from the GROUP ID tibble
unnest(pval, .drop = TRUE)
head(new_mn_pO
sum(new_mn_p$pval < 0.05)/length(new_mn_p$pval)
sum(p.adjust(new_mn_p$pval, method = "bonferroni")<0.05/length(new_mn_p$pval))
p.adjust(new_mn_p$pval, method = "bonferroni")
library("fdrtool")
install.packages("fdrtool")
library("fdrtool")
fdr = fdrtool(new_mn_p$pval, statistic = "pvalue", plot = FALSE)
new_mn_p %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"), fdr = fdrtool(pval,
statistic = "pvalue", plot = F)$qval, BY = p.adjust(pval, method = "BY"))
#We can then applied the above function to each tibble
new_mn_p %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"), fdr = fdrtool(pval,
statistic = "pvalue", plot = F)$qval, BY = p.adjust(pval, method = "BY"))
new_mn_p %>%
dplyr::select(pval) %>%
as.data.frame() %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"),
fdr = fdrtool(pval, statistic="pvalue",plot=F)$qval,
BY=p.adjust(pval,method = "BY")) %>%
mutate(pval = cell_spec(pval, "html", color = ifelse(pval < .05, "red", "blue")),
fwer = cell_spec(fwer, "html", color = ifelse(fwer < .05, "red", "blue")),
fdr = cell_spec(fdr, "html", color = ifelse(fdr < .05, "red", "blue"))) %>%
kable(format = "html", escape = F) %>%
kable_styling("striped", full_width = F)
library(kableExtra)
new_mn_p %>%
dplyr::select(pval) %>%
as.data.frame() %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"),
fdr = fdrtool(pval, statistic="pvalue",plot=F)$qval,
BY=p.adjust(pval,method = "BY")) %>%
mutate(pval = cell_spec(pval, "html", color = ifelse(pval < .05, "red", "blue")),
fwer = cell_spec(fwer, "html", color = ifelse(fwer < .05, "red", "blue")),
fdr = cell_spec(fdr, "html", color = ifelse(fdr < .05, "red", "blue"))) %>%
kable(format = "html", escape = F) %>%
kable_styling("striped", full_width = F)
4/33
knitr::opts_chunk$set(echo = TRUE)
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
# Define a time series object (using ts()) by taking the first observation and last observation
# of a variable of interest, in this case precipitaiton. We indicate that the ts() frequency is
# 1 because we have one observation per year.
TS = ts(mn_tdy_sp_sub_2$prct[1:(length(mn_tdy_sp_sub_2$prct))], frequency = 1, start = c(1966))
#Load the necessary packages.
library(tidyverse)
library(readr)
library(kableExtra)
library(ggplot2)
library(ggfortify)
library(lubridate)
library(raster)
library(raster)
library(sf)
library(ggsn)
#Load the dataset with spatial information
mn_tdy_sp <- read_csv("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG606/Assignment3/mn_tdy_spatial.csv")
mn_tdy_sp_sub <- mn_tdy_sp %>%
#mutate() alters existing variables, specifically TEMP (converting F to C), year (extracting year component), and month (extracting month component)
mutate(TEMP = 5/9 * (TMAX - 32), year = lubridate::year(date), month = lubridate::month(date)) %>%
#We now group the data by year (varname: year) and weather station (varname: COOP_ID)
group_by(year, COOP_ID) %>%
#summarize() will generate new variables. We generate a series of new variables that are the mean of temperature and precipitation. The first observations for the elevation, latitude, and longitude variables are preserved so that we can manipulate them later.
summarize(prct = mean(PRCP, na.rm = T),TEMP = mean(TEMP, na.rm = T), ELEVATION = first(ELEVATION), LATITUDE = first(LATITUDE), LONGITUDE = first(LONGITUDE)) %>%
#We restrict the data to observations after 1965 to improve data coverage and reduce processing time
filter(year>1965) %>%
#Lastly, we re-group the ELEVATION variable by breaking it up into three new groups of -Inf-300 (low), 300-400 (mid), and 450-Inf (high).
mutate(group=cut(ELEVATION, breaks=c(-Inf, 300, 400, Inf), labels=c("LOW","MID","HIGH")))
mn_tdy_sp_sub %>% psych::headTail(10) %>% kable("html") %>%
kable_styling(bootstrap_options = c("striped", "hover")) %>%
column_spec(5)
mn_tdy_sp_sub <- drop_na(mn_tdy_sp_sub)
#Boxplot of mean temperature (Celsius) by elevation group
ggpubr::ggboxplot(mn_tdy_sp_sub, x = "group", y = "TEMP",
#Change how we want to color each boxplot
color = "group",
#Choose custom colors for each boxplot
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
#Specify the order of the boxplot based on existing groups
order = c("LOW", "MID", "HIGH"),
#Assign x and y labels
ylab = "Mean temperature (Celsius)", xlab = "Elevation (meters)", title = "Box plots of mean temperature by elevation")
#Boxplot of mean precipitaiton by elevation group
ggpubr::ggboxplot(mn_tdy_sp_sub, x = "group", y = "prct",
#Change how we want to color each boxplot
color = "group",
#Choose custom colors for each boxplot
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
#Specify the order of the boxplot based on existing groups
order = c("LOW", "MID", "HIGH"),
#Assign x and y labels
ylab = "Mean precipitation (hundreths of inches)", xlab = "Elevation (meters)", title = "Box plots of mean precipitation by elevation")
#Use the manova() command from the stats() package.
manova1 <- manova(cbind(prct, TEMP) ~ group, mn_tdy_sp_sub)
#Print information about the residuals.
manova1
#Obtain a p-value with a specified test of interest.
summary(manova1, test = 'Wilks')
# Recreate the same dataset as before, this time specifying a single COOP_ID of interest
mn_tdy_sp_sub_2 <- mn_tdy_sp %>%
mutate(TEMP = 5/9 * (TMAX - 32), year = lubridate::year(date), month = lubridate::month(date)) %>%
group_by(year, COOP_ID) %>%
summarize(prct = mean(TEMP, na.rm = T), LATITUDE = first(LATITUDE), LONGITUDE = first(LONGITUDE)) %>%
filter(year > 1965, COOP_ID == 210018) %>%
arrange(year)
# Define a time series object (using ts()) by taking the first observation and last observation
# of a variable of interest, in this case precipitaiton. We indicate that the ts() frequency is
# 1 because we have one observation per year.
TS = ts(mn_tdy_sp_sub_2$prct[1:(length(mn_tdy_sp_sub_2$prct))], frequency = 1, start = c(1966))
#We then render the plot
autoplot(TS) + # stat_smooth()+
labs(title = "Average Annual Precipitation for Minnesota Station 210018",
caption = "USHCN daily data available from  https://cdiac.ess-dive.lbl.gov/ftp/ushcn_daily/.\n Label on map is the U.S. Cooperative Observer Network station identification code",
x = "Year", y = "Precipitation (hundreths of inches)")
TS
#Load the package 'Dynamic Linear Models and Time Series Regression'
library(dynlm)
#Load the package 'Dynamic Linear Models and Time Series Regression'
library(dynlm)
#Fit a time series regression
trendall <- dynlm(TS ~ trend(TS))
#Get confidence intervals of intercept and coefficient
confint(trendall, level = 0.95)
#Get summary values
summary(trendall)
10 * -0.02132
library(timetk)
mn_tdy_sp_sub_4 <- mn_tdy_sp_sub %>%
#Reformat the date variable
mutate(date=as.Date(as.character(year),"%Y") ) %>%
#Sort the data by COOP_ID and then year, following by a selection of a few variables
arrange(COOP_ID,year) %>% dplyr::select(COOP_ID,TEMP,year,date) %>%
#Convert the data table to a tibble
as_tibble() %>%
#Group the data by COOP_ID
group_by(COOP_ID) %>%
#For each COOP_ID group, nest a new data table...
nest(.key = "data.tbl") %>%
#...that is explicitly a ts() object (for each of the nested data tables). The year, start, and freq
# are all passed to the tk_ts() function.
mutate(data.ts = map(.x = data.tbl,
.f = tk_ts,
select  = -year,
start   = 1966,
freq    = 1)) %>%
#Now we add a series of new variables beginning with replacing the NAs with interpolated values
mutate(full.ts = map(data.ts, zoo::na.approx)) %>%
#Calculate Theil-Sen slope for each time series (i.e. each COOP_ID)
mutate(fit.tau = map(full.ts, trend::sens.slope)) %>%
#Converting the data to vector format
mutate(data.ve = map(full.ts, as.vector)) %>%
#And lasly conducting Mann-Kendall tests for correlation
mutate(fit.tau2 = map(data.ve, modifiedmk::pwmk))
# We can extract the results for a single one of these new variables by indexing into the new data object
# and then extracting a slide for a given nested value (i.e. 1 through 33 for each of the distinct MN weather stations)
mn_tdy_sp_sub_4$data.ve[[33]]
#Extract the pvalues that have not been adjusted for autocorrelation.
old_mn_p <- mn_tdy_sp_sub_4 %>%
#Generate a new value called pval that extracts the column P-value from the Mann-Kendall test above
mutate(tidy.tbl = map(fit.tau, tidy)) %>%
unnest(tidy.tbl, .drop = TRUE)
#Extract the pvalues that have been adjusted for autocorrelation.
new_mn_p <- mn_tdy_sp_sub_4 %>%
#Generate a new value called pval that extracts the column P-value from the Mann-Kendall test above
mutate(pval = map(fit.tau2, ~.x["P-value"])) %>%
#Unness the pvcal variable from the GROUP ID tibble
unnest(pval, .drop = TRUE)
#Extract the pvalues that have not been adjusted for autocorrelation.
old_mn_p <- mn_tdy_sp_sub_4 %>%
#Generate a new value called pval that extracts the column P-value from the Mann-Kendall test above
mutate(tidy.tbl = map(fit.tau, tidy)) %>%
unnest(tidy.tbl, .drop = TRUE)
#Extract the pvalues that have not been adjusted for autocorrelation.
old_mn_p <- mn_tdy_sp_sub_4 %>%
#Generate a new value called pval that extracts the column P-value from the Mann-Kendall test above
mutate(tidy.tbl = map(fit.tau, broom::tidy)) %>%
unnest(tidy.tbl, .drop = TRUE)
sum(new_mn_p$pval < 0.05)/length(new_mn_p$pval)
sum(old_mn_p$pval < 0.05)/length(old_mn_p$pval)
sum(new_mn_p$pval < 0.05)/length(new_mn_p$pval)
head(old_mn_p)
sum(old.p["p.value"] < 0.05)/count(old.p["p.value"])
sum(old_mn_.p["p.value"] < 0.05)/count(old_mn_.p["p.value"])
sum(old_mn_p.p["p.value"] < 0.05)/count(old_mn_p.p["p.value"])
sum(old_mn_p.["p.value"] < 0.05)/count(old_mn_p.["p.value"])
sum(old_mn_p["p.value"] < 0.05)/count(old_mn_p["p.value"])
sum(new_mn_p$pval < 0.05)/length(new_mn_p$pval)
sum(old_mn_p["p.value"] < 0.05)/count(old_mn_p["p.value"])
Lastly, we might be interested in conceptualizing the issue of multiple testing from the perspective of false discovery. Thus, we will turn to *q-values* rather than p-values.
old_mn_p$
```{r, message = F, warning=F}
library("fdrtool")
# Create a new object called fdr. Here we consider only the Mann-Kendall p-values
fdr = fdrtool(new_mn_p$pval, statistic = "pvalue", plot = FALSE)
fdr
Lastly, we might be interested in conceptualizing the issue of multiple testing from the perspective of false discovery. Thus, we will turn to *q-values* rather than p-values (as they relate a given p-value to the distribution of all p-values being considered).
```{r, message = F, warning=F}
library("fdrtool")
# Create a new object called fdr. Here we consider only the Mann-Kendall p-values
fdr = fdrtool(new_mn_p$pval, statistic = "pvalue", plot = FALSE)
# Freview the generated fdr object
fdr
The new `fdr` object stores a series of pvalues, qvalues, and other test statistics. We can apply this function to each COOP_ID tibble...
```{r, message = F, warning=F}
#We can then applied the above function to each COOP_ID tibble
new_mn_p %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"),
#Above: family wide error rate
fdr = fdrtool(pval, statistic = "pvalue", plot = F)$qval,
#Above: false discovery rate
BY = p.adjust(pval, method = "BY"))
library(kableExtra)
new_mn_p %>%
dplyr::select(pval) %>%
as.data.frame() %>%
mutate(fwer = p.adjust(pval, method = "bonferroni"),
fdr = fdrtool(pval, statistic="pvalue",plot=F)$qval,
BY=p.adjust(pval,method = "BY")) %>%
mutate(pval = cell_spec(pval, "html", color = ifelse(pval < .05, "red", "blue")),
fwer = cell_spec(fwer, "html", color = ifelse(fwer < .05, "red", "blue")),
fdr = cell_spec(fdr, "html", color = ifelse(fdr < .05, "red", "blue"))) %>%
kable(format = "html", escape = F) %>%
kable_styling("striped", full_width = F)
.27*33
knitr::opts_chunk$set(echo = TRUE)
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
#Calculate proportion of weather stations demonstrating 'significant' trend using Sen's p-values
sum(old_mn_p["p.value"] < 0.05)/count(old_mn_p["p.value"])
# Download tests datasets using original ARCOS package
install.packages("arcos")
16* 1.5
16 * 8
400-25
375/2
400/2
200-128
540
540-500
40/8
545-484
545 - 485
16*3
545 - 48
/2
497/2
248*.93
10.31 + 56.53
28+366.50+7
library(arcos)
pharm_latlon(, county, state, key)
pharm_latlon(, county, state, key = 'WaPo')
pharm_latlon(input_county, input_state, input_key)
input_county = 'Hennepin'
input_state = 'MN'
input_key = 'WaPo'
pharm_latlon(input_county, input_state, input_key)
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests')
# Test function 1: pharm_latlon
func1_output <- pharm_latlon(input_county, input_state, input_key)
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests_datasets/func1_output.csv')
ls
getwd()
list.files()
setwd("/Users/jefferysauer/Dropbox/PhD_Courses/
")"
setwd("/Users/jefferysauer/Dropbox/PhD_Courses/")
setwd("/Users/jefferysauer/Dropbox/")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses")
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG_788P")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy")
list.files()
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests")
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/tests/")
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/")
setwd("/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/")
list.files()
list.files()
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/ests_datasets/func1_output.csv')
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func1_output.csv')
write.csv(func3_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func3_output.csv')
# Test function 3: pharm_tracts
func2_output <- pharm_tracts(input_county, input_state, input_key)
write.csv(func3_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func3_output.csv')
# Test function 3: pharm_tracts
func3_output <- pharm_tracts(input_county, input_state, input_key)
write.csv(func3_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func3_output.csv')
# Test function 5: buyer_addresses
func5_output <- buyer_addresses(input_county, input_state, input_key)
write.csv(func5_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func3_output.csv')
write.csv(func5_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func5_output.csv')
write.csv(func3_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func3_output.csv')
# Test function 3: pharm_tracts
func3_output <- pharm_tracts(input_county, input_state, input_key)
write.csv(func1_output, file = '/Users/jefferysauer/Dropbox/Maryland/PhD_Courses/GEOG788P/jeffsauer_MnM4SDS_project/arcospy/arcospy/tests_datasets/func1_output.csv')
# Test function 1: pharm_latlon
func1_output <- pharm_latlon(input_county, input_state, input_key)
